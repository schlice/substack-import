---
title: '"Untitled Post"'
tags: []
date: '2000-01-01'
layout: post
---

<h2>Answer</h2>
<div>

{.rendered_qtext}

</div>

<div>

**Content:** []{.rendered_qtext}

**I believe that Apple** ***should*** **be compelled to comply**, and
ultimately, I believe that it will be good for security and privacy in
the future.

**Here\'s the reason.**

The government is not asking for a \"backdoor\" like Tim Cook
disingenuously stated. The government is asking for the following:

- Turn off the \"10 failed passcodes and you wipe\" function
- Turn off the delay between failed passcodes
- Add support for external PIN entry.

The FBI will then brute-force the passcode (for the non-techies, this
means that they will use an external system to try every passcode
combination, in sequence, until they hit the right one. Also note that
the government is not requiring Apple to build the feature into all iOS
releases, nor is it preventing Apple from immediately reverting such a
change. It\'s also not required to actually release the code to the FBI;
all the work can be done at Apple\'s headquarters.

Here\'s where this is Apple\'s problem: the iPhone 5C\'s security
algorithms are all built into the software. Since then, they are built
into a piece of hardware called the Secure Enclave, which can only be
unlocked using the fingerprint scanner or the passcode. It\'s arguable
that Apple could possibly update the software on the Secure Enclave
through a patch as well, but they\'re not saying.

The bottom line here is this: Apple released a product which can already
either be updated while it is still passcode-locked, or that the
contents of the flash drives can be downloaded to a VM and executed
there. The simple fact that Apple did not immediately state that it was
technically impossible to do either of these things means that they do
have the capability to do so.

This also means that Apple can load a custom OS ***designed to run on
that IMEI only*** (which they can do) which will disable the functions
listed. They don\'t even have to give the code to the FBI, they only
need to run it and unlock the phone. Even if the FBI got hold of
Apple\'s crippled software and tried to reverse-engineer it to run on
other phones, it\'s ***digitally signed***, so any modification of the
code will cause it to fail, rendering it unusable.

Apple\'s concerns about making \"backdoors\" which could unlock any
iDevice in existence are simply fear-mongering, and as I already stated,
are disingenuous.

**Why is this good for security?**

We need to *demand* from our hardware manufacturers smartphones that do
not have similar security holes that the government can demand through
the court a manufacturer breach.

We can\'t trust the government to do the right thing all the time. So
what\'s the alternative? We demand a tougher smartphone. We need to
demand security that even the manufacturer cannot break. We want Apple
(and other manufacturers) to get their hardware to a point where *even
they* will not be able to break it. This can only mean more secure
smartphones in the future.

Which, in the long run, will be good for us.

(EDIT) The government released a scathing renewal of its filing on
Friday, stating, among other things, that Apple has overblown the issue
and has made misleading statements. In part, the updated filing says:

> The order does not, as Apple\'s public statement alleges, require
> Apple to create or provide a \"backdoor\" to every iPhone\...It does
> not provide \'hackers and criminals\' access to iPhones\...and does
> not give the government \"the power to reach into anyone\'s device\"
> without a warrant or court authorization.
>
> No one outside Apple would have access to the software required by the
> order unless Apple itself chose to share it.

Apple\'s concern is that all iPhones would be affected, ***but not by
the requested software.*** Apple is attempting to make a \"slippery
slope\" argument by stating that if the prosecutors in this case are
victorious, other prosecutors around the country will start asking for
the same technology, and then other countries would follow. Apple also
stated that this is not a simple fix, it will take weeks or months to
develop.

The government filing states that Apple is failing to do its civic duty
as a good corporate citizen of the country:

> This court should not entertain an argument that fulfilling basic
> civic responsibilities of any American citizen or company \--
> complying with a lawful court order \-- could be obviated because the
> company prefers to market itself as providing privacy protections that
> make it infeasible to comply with court-issued warrants.

Finally, the government made the same point that I did above: Apple
never said it can\'t do it (emphasis mine):

> At no point has Apple ever said that it does not have the technical
> ability to comply with the order, or that the order asks Apple to
> undertake an unreasonable challenging software development task. **On
> this point, Apple\'s silence speaks volumes.**

</div>

<div>


</div>

<div>

**Content language:** English

</div>

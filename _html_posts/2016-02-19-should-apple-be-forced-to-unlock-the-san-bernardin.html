---
title: '"Untitled Post"'
tags: []
date: '2000-01-01'
layout: post
---
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Quora Answer</title>
</head>
<body>
<pre>
</pre>
<hr>
<br><br><h2>Answer</h2><br><div><br><br><br><br></div><br><br><div><br><br>Content: <br><br>I believe that Apple *should* be compelled to comply, and<br>ultimately, I believe that it will be good for security and privacy in<br>the future.<br><br>Here\'s the reason.<br><br>The government is not asking for a \"backdoor\" like Tim Cook<br>disingenuously stated. The government is asking for the following:<br><br>- Turn off the \"10 failed passcodes and you wipe\" function<br>- Turn off the delay between failed passcodes<br>- Add support for external PIN entry.<br><br>The FBI will then brute-force the passcode (for the non-techies, this<br>means that they will use an external system to try every passcode<br>combination, in sequence, until they hit the right one. Also note that<br>the government is not requiring Apple to build the feature into all iOS<br>releases, nor is it preventing Apple from immediately reverting such a<br>change. It\'s also not required to actually release the code to the FBI;<br>all the work can be done at Apple\'s headquarters.<br><br>Here\'s where this is Apple\'s problem: the iPhone 5C\'s security<br>algorithms are all built into the software. Since then, they are built<br>into a piece of hardware called the Secure Enclave, which can only be<br>unlocked using the fingerprint scanner or the passcode. It\'s arguable<br>that Apple could possibly update the software on the Secure Enclave<br>through a patch as well, but they\'re not saying.<br><br>The bottom line here is this: Apple released a product which can already<br>either be updated while it is still passcode-locked, or that the<br>contents of the flash drives can be downloaded to a VM and executed<br>there. The simple fact that Apple did not immediately state that it was<br>technically impossible to do either of these things means that they do<br>have the capability to do so.<br><br>This also means that Apple can load a custom OS ***designed to run on<br>that IMEI only*** (which they can do) which will disable the functions<br>listed. They don\'t even have to give the code to the FBI, they only<br>need to run it and unlock the phone. Even if the FBI got hold of<br>Apple\'s crippled software and tried to reverse-engineer it to run on<br>other phones, it\'s *digitally signed*, so any modification of the<br>code will cause it to fail, rendering it unusable.<br><br>Apple\'s concerns about making \"backdoors\" which could unlock any<br>iDevice in existence are simply fear-mongering, and as I already stated,<br>are disingenuous.<br><br>Why is this good for security?<br><br>We need to *demand* from our hardware manufacturers smartphones that do<br>not have similar security holes that the government can demand through<br>the court a manufacturer breach.<br><br>We can\'t trust the government to do the right thing all the time. So<br>what\'s the alternative? We demand a tougher smartphone. We need to<br>demand security that even the manufacturer cannot break. We want Apple<br>(and other manufacturers) to get their hardware to a point where *even<br>they* will not be able to break it. This can only mean more secure<br>smartphones in the future.<br><br>Which, in the long run, will be good for us.<br><br>(EDIT) The government released a scathing renewal of its filing on<br>Friday, stating, among other things, that Apple has overblown the issue<br>and has made misleading statements. In part, the updated filing says:<br><br>> The order does not, as Apple\'s public statement alleges, require<br>> Apple to create or provide a \"backdoor\" to every iPhone\...It does<br>> not provide \'hackers and criminals\' access to iPhones\...and does<br>> not give the government \"the power to reach into anyone\'s device\"<br>> without a warrant or court authorization.<br>><br>> No one outside Apple would have access to the software required by the<br>> order unless Apple itself chose to share it.<br><br>Apple\'s concern is that all iPhones would be affected, ***but not by<br>the requested software.*** Apple is attempting to make a \"slippery<br>slope\" argument by stating that if the prosecutors in this case are<br>victorious, other prosecutors around the country will start asking for<br>the same technology, and then other countries would follow. Apple also<br>stated that this is not a simple fix, it will take weeks or months to<br>develop.<br><br>The government filing states that Apple is failing to do its civic duty<br>as a good corporate citizen of the country:<br><br>> This court should not entertain an argument that fulfilling basic<br>> civic responsibilities of any American citizen or company \--<br>> complying with a lawful court order \-- could be obviated because the<br>> company prefers to market itself as providing privacy protections that<br>> make it infeasible to comply with court-issued warrants.<br><br>Finally, the government made the same point that I did above: Apple<br>never said it can\'t do it (emphasis mine):<br><br>> At no point has Apple ever said that it does not have the technical<br>> ability to comply with the order, or that the order asks Apple to<br>> undertake an unreasonable challenging software development task. **On<br>> this point, Apple\'s silence speaks volumes.**<br><br></div><br><br><div><br><br><br></div><br><br><div><br><br>Content language: English<br><br></div><br>
</body>
</html>
